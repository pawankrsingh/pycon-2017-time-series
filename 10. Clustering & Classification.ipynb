{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pylab as plt\n",
    "\n",
    "from matplotlib.pylab import rcParams\n",
    "rcParams['figure.figsize'] = 15, 6\n",
    "\n",
    "from datetime import datetime\n",
    "from scipy.cluster.hierarchy import dendrogram, linkage\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.metrics.pairwise import pairwise_distances\n",
    "from math import sqrt\n",
    "from scipy.spatial.distance import squareform"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "words = pd.read_csv('data/50words_TEST.csv', index_col = 0, header = None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "words.index"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Let's take a look at some of the words 'on average'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "for i in range(7):\n",
    "    row = words.groupby(words.index).mean().iloc[i]\n",
    "    row.plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### We can also check to see whether the 'average' matches the individual plot for a given type\n",
    "\n",
    "First, the 'average'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "word_type = 7\n",
    "row = words.groupby(words.index).mean().iloc[word_type-1]\n",
    "row.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "word_type = 7\n",
    "row = words.groupby(words.index).median().iloc[word_type-1]\n",
    "row.plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next the full sample of all those words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "for i in range(words[words.index == word_type].shape[0]):\n",
    "    row = words[words.index == word_type].iloc[i]\n",
    "    row.plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Let's try to code up the sensible distance function to describe the distance between two times series"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# courtesy of http://alexminnaar.com/time-series-classification-and-clustering-with-python.html\n",
    "# %load snippets/dtwdistance.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "chosen_words = words[words.index == word_type]\n",
    "s1 = chosen_words.iloc[2]\n",
    "s2 = chosen_words.iloc[3]\n",
    "print(type(s1))\n",
    "DTWDistance(s1.values, s2.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "s3 = words.iloc[0]\n",
    "DTWDistance(s1.values, s3.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "s3 = words.iloc[0]\n",
    "DTWDistance(s2.values, s3.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "plt.plot(s1)\n",
    "plt.plot(s2)\n",
    "plt.plot(s3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compare the performance of Euclidean distance with that of DTDW for s1, s2, s3 as specified above"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# %load snippets/euclidedistance.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "EuclidDistance(s1.values, s2.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "EuclidDistance(s3.values, s2.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "EuclidDistance(s1.values, s3.values)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Can you classify a random row by determining which 'mean' curve it is closest to? How successful is this?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "mean_curve = {}\n",
    "for j in range(1,len(set(words.index))):\n",
    "    row = words[words.index == j].mean()\n",
    "    mean_curve[j] = row"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "test_word = words[words.index == 5].iloc[3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "distance_dict = {key:DTWDistance(test_word.values, value.values) for (key, value) in mean_curve.items() }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from collections import OrderedDict\n",
    "\n",
    "OrderedDict(sorted(distance_dict.items(), key=lambda t: t[1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Can you cluster the words using the DTW metric?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Yes, but this would take a really long time, so we're not going to do it"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Instead cluster with features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "max_location = []\n",
    "first_local_max_location = []\n",
    "second_local_max_location = []\n",
    "num_inflections = []\n",
    "ratio_first_local_max_to_abs_max = []\n",
    "word_type = []\n",
    "\n",
    "def smooth(y, box_pts):\n",
    "    box = np.ones(box_pts)/box_pts\n",
    "    y_smooth = np.convolve(y, box, mode='same')\n",
    "    return y_smooth\n",
    "\n",
    "for row in range(words.shape[1]):\n",
    "    word_type.append(words.index[row])\n",
    "    \n",
    "    # locations of maximum, locations of first and second inflection points, number of inflection points\n",
    "    w = words.iloc[row]\n",
    "    \n",
    "    # max point\n",
    "    max_location.append(w.idxmax())\n",
    "    \n",
    "    # local maxima and minima\n",
    "    w_arr = np.array(w)\n",
    "    w_arr = smooth(w_arr, 10)\n",
    "    \n",
    "    lows = np.where(np.r_[True, w_arr[1:] < w_arr[:-1]] & np.r_[w_arr[:-1] < w_arr[1:], True])\n",
    "    lows = lows[0]\n",
    "    mask = ((265 > lows ) & (lows > 5))\n",
    "    lows = lows[mask]\n",
    "    \n",
    "    highs = np.where(np.r_[True, w_arr[1:] > w_arr[:-1]] & np.r_[w_arr[:-1] > w_arr[1:], True])\n",
    "    highs = highs[0]\n",
    "    mask = ((265 > highs) & (highs > 5))\n",
    "    highs = highs[mask]\n",
    "    \n",
    "    first_local_max_location.append(highs[0])\n",
    "    second_local_max_location.append(highs[1])\n",
    "\n",
    "    ratio_first_local_max_to_abs_max.append(w_arr[highs[0]]/w_arr[w.idxmax()])\n",
    "    \n",
    "    num_inflections.append(len(highs) + len(lows))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "results = pd.DataFrame({'word_type' : word_type,\n",
    "                        'max_location': max_location, \n",
    "                        'first_local_max_location' : first_local_max_location,\n",
    "                        'second_local_max_location' : second_local_max_location,\n",
    "                        'num_inflections' : num_inflections,\n",
    "                        'ratio_first_local_max_to_abs_max' : ratio_first_local_max_to_abs_max})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "results.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.cluster import KMeans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "estimator = KMeans(n_clusters=50)\n",
    "estimator.fit(results.drop('word_type', axis=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "results['labels'] = estimator.labels_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "results[results.word_type == 5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [Root]",
   "language": "python",
   "name": "Python [Root]"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  },
  "widgets": {
   "state": {},
   "version": "1.1.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
